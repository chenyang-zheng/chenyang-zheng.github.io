<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Prompt Engineering for LLM Cot | Chenyang&#39;s Eureka</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="Some thoughts on Prompt Optimization and Instructional Design for LLM CoT:
F(Instruction) = P(Chain of Thought) # instruction and rules are designed for LLM CoT
F(CoT) = P(thinking | Instruction) # CoT is the chain of thought, the thinking process of the model
F(Cot) = F(thinking) = P(answer) # After sorted CoT process based on the instruction, the final answer is generated.
Instruction complexity will affect the LLM understand the task, concise one gets better performance.">
    <meta name="generator" content="Hugo 0.133.1">
    
    
    
    
      <meta name="robots" content="noindex, nofollow">
    
    

    
<link rel="stylesheet" href="/ananke/css/main.min.css" >



    

    
      

    

    

    
      <link rel="canonical" href="https://chenyang-zheng.github.io/posts/cot-and-prompt/">
    

    <meta property="og:url" content="https://chenyang-zheng.github.io/posts/cot-and-prompt/">
  <meta property="og:site_name" content="Chenyang&#39;s Eureka">
  <meta property="og:title" content="Prompt Engineering for LLM Cot">
  <meta property="og:description" content="Some thoughts on Prompt Optimization and Instructional Design for LLM CoT:
F(Instruction) = P(Chain of Thought) # instruction and rules are designed for LLM CoT
F(CoT) = P(thinking | Instruction) # CoT is the chain of thought, the thinking process of the model
F(Cot) = F(thinking) = P(answer) # After sorted CoT process based on the instruction, the final answer is generated.
Instruction complexity will affect the LLM understand the task, concise one gets better performance.">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-08-26T20:02:20+08:00">
    <meta property="article:modified_time" content="2024-08-26T20:02:20+08:00">

  <meta itemprop="name" content="Prompt Engineering for LLM Cot">
  <meta itemprop="description" content="Some thoughts on Prompt Optimization and Instructional Design for LLM CoT:
F(Instruction) = P(Chain of Thought) # instruction and rules are designed for LLM CoT
F(CoT) = P(thinking | Instruction) # CoT is the chain of thought, the thinking process of the model
F(Cot) = F(thinking) = P(answer) # After sorted CoT process based on the instruction, the final answer is generated.
Instruction complexity will affect the LLM understand the task, concise one gets better performance.">
  <meta itemprop="datePublished" content="2024-08-26T20:02:20+08:00">
  <meta itemprop="dateModified" content="2024-08-26T20:02:20+08:00">
  <meta itemprop="wordCount" content="179">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Prompt Engineering for LLM Cot">
  <meta name="twitter:description" content="Some thoughts on Prompt Optimization and Instructional Design for LLM CoT:
F(Instruction) = P(Chain of Thought) # instruction and rules are designed for LLM CoT
F(CoT) = P(thinking | Instruction) # CoT is the chain of thought, the thinking process of the model
F(Cot) = F(thinking) = P(answer) # After sorted CoT process based on the instruction, the final answer is generated.
Instruction complexity will affect the LLM understand the task, concise one gets better performance.">

	
  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  <header>
    <div class="bg-black">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="/" class="f3 fw2 hover-white no-underline white-90 dib">
      
        Chenyang&#39;s Eureka
      
    </a>
    <div class="flex-l items-center">
      

      
      
<div class="ananke-socials">
  
</div>

    </div>
  </div>
</nav>

    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked ttu">
          
        Posts
      </aside>
      










  <div id="sharing" class="mt3 ananke-socials">
    
  </div>


      <h1 class="f1 athelas mt3 mb1">Prompt Engineering for LLM Cot</h1>
      
      
      
      
      <time class="f6 mv4 dib tracked" datetime="2024-08-26T20:02:20+08:00">August 26, 2024</time>
      

      
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><p><strong>Some thoughts on Prompt Optimization and Instructional Design for LLM CoT</strong>:</p>
<p>F(Instruction) = P(Chain of Thought) # instruction and rules are designed for LLM CoT</p>
<p>F(CoT) = P(thinking | Instruction) # CoT is the chain of thought, the thinking process of the model</p>
<p>F(Cot) = F(thinking) = P(answer) # After sorted CoT process based on the instruction, the final answer is generated.</p>
<p>Instruction complexity will affect the LLM understand the task, concise one gets better performance.</p>
<p>Divide and conquer is also a good method to optimize the CoT and workflow. Chain of multiple tasks instead of one complex task might be a better idea.
Supported by <a href="https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-prompts">Chain complex prompts for stronger performance</a></p>
<h2 id="reference">Reference</h2>
<ul>
<li><a href="https://arxiv.org/abs/2201.11903">Chain of Thought Prompting Elicits Reasoning in Large Language Models</a></li>
<li><a href="https://llama.meta.com/docs/how-to-guides/prompting">Llama 3: How to Prompt LLMs</a></li>
<li><a href="https://github.com/elder-plinius/L1B3RT45">Jailbreak Prompt</a></li>
<li><a href="https://github.com/anthropics/anthropic-cookbook/blob/main/misc/metaprompt.ipynb">Anthropic Metaprompt</a></li>
<li><a href="https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/be-clear-and-direct">Claude: Be Clear and Direct</a></li>
<li><a href="https://github.com/anthropics/prompt-eng-interactive-tutorial">Claude: Prompt Engineering Interactive Tutorial</a></li>
</ul>
<h2 id="todo">TODO:</h2>
<ul>
<li><input disabled="" type="checkbox"> Read all the reference materials.</li>
<li><input disabled="" type="checkbox"> <a href="https://arxiv.org/abs/2201.11903">Chain of Thought Prompting Elicits Reasoning in Large Language Models</a></li>
<li><input disabled="" type="checkbox"> <a href="https://llama.meta.com/docs/how-to-guides/prompting">Llama 3: How to Prompt LLMs</a></li>
<li><input disabled="" type="checkbox"> <a href="https://github.com/elder-plinius/L1B3RT45">Jailbreak Prompt</a></li>
<li><input disabled="" type="checkbox"> <a href="https://github.com/anthropics/anthropic-cookbook/blob/main/misc/metaprompt.ipynb">Anthropic Metaprompt</a></li>
<li><input disabled="" type="checkbox"> <a href="https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/be-clear-and-direct">Claude: Be Clear and Direct</a></li>
<li><input disabled="" type="checkbox"> <a href="https://github.com/anthropics/prompt-eng-interactive-tutorial">Claude: Prompt Engineering Interactive Tutorial</a></li>
</ul>
<ul class="pa0">
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="https://chenyang-zheng.github.io/" >
    &copy;  Chenyang's Eureka 2024 
  </a>
    <div>
<div class="ananke-socials">
  
</div>
</div>
  </div>
</footer>

  </body>
</html>
